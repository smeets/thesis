\chapter{Introduction}

In 2014 a report on Wi-Fi adoption found that 25\% of households, all over the world, had Wi-Fi networks set up. In households with fixed-line broadband access, 65\% had set up a Wi-Fi network\cite{smith}. The report also states that the number of Wi-Fi-enabled devices is projected to increase. 

Naturally, consumers today have higher expectations regarding network throughput and latency than the IEEE 802.11 standard was designed for back in 1997. In recent years, the Wi-Fi label has become hugely popular and the standard been catching up ever since it was introduced beyond the corporate sector, for which it was originally intended, with almost annual extensions.

One limitation all wireless networking technologies have to consider is radio interference. Some protocols implement ALOHA-style protocols with no coordination between devices, relying on collision detection techniques and subsequent retransmission. IEEE 802.11 implements a \emph{distributed contribution function} (DCF) which is resposible for controlling access to the medium.

Even though newer routers today are able to automatically (re)configure themselves based on analysis of neighbouring networks, they are not guaranteed to be optimal since they have a local view of the network. Older routers rely on manual configuration. This configuration is not strictly an issue with the standard, but rather with how the routers are being deployed. One can think of the deployment process as being decentralised—each household purchases and configures their own router. 

With existing IEEE 802.11 models it is possible to predict configuration effects. However, few, if not none, implementations conform to the theoretical models. This work aims to evaluate IEEE 802.11 models with end-user data and analyse if, and how, these models may be applicable.

% Centralised configuration is still not on the map for the foreseeable future. Expert systems are already in-place. The task becomes on how to improve existing systems---can we come up with a system which guarantees that a recommended change results in an improvement? This would require extensive simulation of the network and the ability to predict the effect of a change in a configuration parameter.




This master thesis aims to be a step in this direction: evaluate existing Wi-Fi models to see if they are useful in real-world settings.
% em —


% Recommend configuration based on both detailed and wide view of network performance.

% To recommend a change it must lead to improvement in some aspect.

% How to be sure of this? Model the network and simulate what happens when the change is made.

% This requires competent Wi-Fi models.

% Must have clear definition of a competent Wi-Fi model is.

% Wi-Fi models with good performance in simulated tests need not be as good in the real world.

% So we have to test this, and we need the data to do it.

% Telenor now has a good platform for us to get the data.

% But can we trust it? Perhaps the logging is inaccurate?

% So we need to analyse the quality of the data.

%  - is it accurate?
%  - is it precise?

% Experiments will be conducted and results will impact model testing and evaluation.
